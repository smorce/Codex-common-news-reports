# AI News Report (https://ai-news.dev/)

- Generated at: 2026-02-06T15:58:24.0742787+09:00
- Articles: 3

## AI要約だけ見て「検索終了」は6割超　ドコモ調査
- Date: 2026-02-05T19:07:00+09:00

### Executive Summary
- NTTドコモのモバイル社会研究所がAI要約と検索行動の調査結果を公開した。
- AI要約だけを見て検索を終える人が6割超という結果が示された。
- 「ほとんど」「よく」「時々」やめるの合計は64%だった。
- 10〜20代と50〜70代女性で検索停止率が高い傾向が見られた。
- AI生成物の確認をAIに任せてもよいと考える層ほどゼロクリックが多い。
- 理由理解より答え重視の態度もゼロクリックと関連している。
- 2025年11月に全国15〜79歳1267人のWeb調査で実施された。

### Key Findings
- AI要約だけで検索を終える人が6割超という調査結果が示された。 [^]
  - Footnote: AI要約だけ見て検索を終える人が6割超――NTTドコモのモバイル社会研究所は2月5日、このような調査結果を公開した。
- 検索をやめる割合の合計は64%で、内訳が示された。 [^]
  - Footnote: AI要約に満足して検索を「ほとんど（9割以上）やめる」と答えた人は10％、「よく（7～8割くらい）やめる」は19％、「時々（4～6割くらい）やめる」は35％で、合計64％だった。
- 10〜20代と50〜70代女性は検索停止率が高い傾向にある。 [^]
  - Footnote: 年代・性別ごとに見ると、10～20代と50～70代女性は「ほとんどやめる」「よくやめる」を合わせた割合が約4割で、他の層より高い傾向が見られた。
- AI生成物をAIに任せて確認する、答え重視の態度はゼロクリックと関連する。 [^]
  - Footnote: 「生成AIで作成したテキストを宿題や仕事で提出する際、生成物の確認作業も人よりAIに任せてよい」と考える人や、「問題の答えがなぜそうなるのかを理解するよりも、単純に答えだけを知っている方がよい」と考える人ほど、ゼロクリック検索をしていることが判明したという。
- 調査は2025年11月に全国15〜79歳1267人を対象としたWeb調査で実施された。 [^]
  - Footnote: 調査は2025年11月、全国の15～79歳男女1267人を対象に、Webで実施した。

### References
- https://www.itmedia.co.jp/aiplus/articles/2602/05/news131.html

## 推論モデルは「性格や知識が異なる複数人による会議」をシミュレートして精度を向上させているとの研究結果
- Date: 2026-02-05T15:00:00+09:00

### Executive Summary
- 研究チームが推論モデルの内部プロセスを分析した。
- 明示的な指示がなくても内的会議のシミュレーションが発達すると報告された。
- 「society of thought」と呼ばれる多様なエージェント会議が鍵だという。
- 認知的多様性と真の異論が問題解決能力を高めると説明される。
- DeepSeek-R1では計画者と批判的検証者の議論が誤り修正に寄与した。
- 創造的タスクでも複数ペルソナが議論して品質を調整した。
- 議論データの学習が精度に重要で、誤答議論データでも有効と示唆された。

### Key Findings
- 主要な推論モデルは明示的な指示なしに内的会議のシミュレーションを発達させる。 [^]
  - Footnote: 研究チームは、DeepSeek-R1やQwQ-32Bなどの主要な推論モデルが行う推論ステップを分析したところ、明示的な指示がなくても自律的に内的会議のシミュレーションを発達させることを発見しました。
- 内的会議は「society of thought」で、多様な視点や性格特性のマルチエージェント会議を指す。 [^]
  - Footnote: この内的会議は「society of thought(思考の社会)」と呼ばれ、多様な視点や性格特性、専門領域の知識を含むマルチエージェントによる会議をシミュレートするとのこと。
- 認知的多様性と真の異論が問題解決能力を高めると論じられている。 [^]
  - Footnote: 「専門知識や性格特性の多様性から生じる認知的多様性は、特に真の異論が伴う場合に問題解決能力を高めます」と論じています。
- 内的エージェント間の対話で推論の正しさをチェックし、バイアスやおべっかを回避できる。 [^]
  - Footnote: 推論モデルは異なる内部エージェント間の会話をシミュレートすることで、推論の正しさや問題点についてチェックし、望ましくないバイアスやおべっかといった落とし穴を回避できるとのこと。
- DeepSeek-R1は計画者と批判的検証者を含む内部エージェントの議論をシミュレートした。 [^]
  - Footnote: 実際に研究チームがDeepSeek-R1に複雑な有機化学合成問題を与えたところ、DeepSeek-R1は「Planner(計画者)」と「Critical Verifier(批判的検証者)」を含む複数の内部エージェントによる議論をシミュレートしました。
- 議論データの重要性が示され、誤答に至る会話データでも同等精度が得られた。 [^]
  - Footnote: 実際にエヴァンズ氏らが「間違った答えにつながる会話データ」を使ってモデルを訓練したところ、「正しい答えにつながるデータ」で訓練した時と同様の精度を発揮したとのこと。

### References
- https://gigazine.net/news/20260205-ai-simulate-internal-debate-improve-accuracy/

## 素人がAIでアプリ開発するも「公開の壁」に直面したため、現役プロに教えを乞う連載始めます
- Date: 2026-02-06T09:00:00+09:00

### Executive Summary
- 非エンジニアでもAIでアプリを作れる時代が到来したと述べる。
- 一方で「公開の壁」と安全性への不安が大きな課題として描かれる。
- 筆者はGemini CanvasやClaude Codeで小さな業務ツールを作った経験を紹介。
- 公開時の責任やセキュリティ、他環境でのトラブルが不安の中心にある。
- 現役エンジニアは公開サービスには専門知識が必要と指摘する。
- 安全な環境やMVPから始める段階的アプローチを提案している。
- 次回はGoogle AI Studioでウイスキー認識アプリの試作に進む。

### Key Findings
- 生成AIにより、専門知識がなくても言葉だけでアプリ開発が可能になったと述べる。 [^]
  - Footnote: 生成AIが自然言語を理解し、自らコードを生成できるようになったことで、専門知識がなくても言葉だけでアプリを開発できるようになった。
- 筆者はGemini CanvasやClaude Codeで小さなツールをAIに作らせた経験がある。 [^]
  - Footnote: 実際に「Gemini Canvas」や「Claude Code」を使い、日常の業務で必要となる「文字数カウント」ツールや、会議録音データの「音声ファイル分割」アプリなど、自分が欲しいと思ったちょっとしたソフトをその場でAIに指示して作らせてみた。
- 公開段階に進むと恐怖が生まれると述べ、公開の壁がテーマになっている。 [^]
  - Footnote: しかし、ここから一歩先に進もうとすると、突然足がすくむ。
- AIが書いたコードの正しさや安全性を判断できないことが不安の核心である。 [^]
  - Footnote: 「AIが書いたコードの中身が正しいのか、安全なのか」を判断する術を持たない。
- 公開サービスや個人情報・決済領域は、無知のまま公開するのは危険だと専門家が指摘した。 [^]
  - Footnote: 外部に公開するサービスや、ユーザー管理機能、権限管理、個人情報、決済のようなセキュリティに大きく関わる領域では『何もわからない』状態で公開するのは危険です
- 安全な環境や自分だけで完結する機能から始める段階的な進め方が提案された。 [^]
  - Footnote: まずは、自分だけで完結する機能、あるいはGoogleなどが用意している安全な環境の上で動くものから始めましょう

### References
- https://forest.watch.impress.co.jp/docs/serial/vibcode/2083579.html
